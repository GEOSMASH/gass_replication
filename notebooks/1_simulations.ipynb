{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f061d62-aa56-4248-86b7-17deec76a28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liaom/.local/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_path = os.path.abspath('')\n",
    "parent_path = os.path.dirname(current_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.insert(0, parent_path)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for generating simulated data\n",
    "import csv \n",
    "from pointpats import PoissonPointProcess, as_window \n",
    "from libpysal.cg import Point, Polygon\n",
    "\n",
    "# for classic backfitting\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "from copy import deepcopy\n",
    "from spglm.iwls import _compute_betas_gwr\n",
    "from mgwr.search import golden_section\n",
    "\n",
    "# for modified backfitting\n",
    "from smoother import ConstantTerm, LinearTerm, DistanceWeighting, SpatialWeightSmoother \n",
    "from gass import GASS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e121349-7b2b-4608-98bb-6809abc343dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Repeated Simulation: Classic V.S Modified Backfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be8650-a9f8-4942-9bec-a733631f2c23",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256a10f6-62f5-4fcf-b411-2f5b1b9f1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sigma_for_filename(sigma):\n",
    "    \"\"\"\n",
    "    Format the sigma values to be used in the filename.\n",
    "    - Remove the negative sign.\n",
    "    - Replace the decimal point with 'pt'.\n",
    "    - Do not include the leading zero if the absolute value is less than 1.\n",
    "    - Do not include trailing zeros after the decimal point.\n",
    "    \"\"\"\n",
    "    # Convert sigma to a positive number and create a formatted string\n",
    "    formatted_sigma = '{:.2f}'.format(abs(sigma)).lstrip('0').replace('.', 'pt').rstrip('pt0')\n",
    "    \n",
    "    return formatted_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3752b97-5541-4835-b6c0-01850d50f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic Backfitting\n",
    "\n",
    "def classic_backfit(y, X, w, term_mapping, verbose = False, max_iter = 50, tol = 1e-8):\n",
    "    n,k = X.shape\n",
    "    betas = _compute_betas_gwr(y, X, w.reshape((-1, 1)))[0]\n",
    "    XB = np.multiply(betas.T, X)\n",
    "    yhat = np.dot(X, betas)\n",
    "    err = y.reshape((-1, 1)) - yhat\n",
    "    scores = []\n",
    "    delta = 1e6\n",
    "    \n",
    "    sigs = [-1, -1]\n",
    "\n",
    "    for n_iter in range(1, max_iter + 1):\n",
    "        new_XB = np.zeros_like(X)\n",
    "        params = np.zeros_like(betas)\n",
    "\n",
    "        for j in range(k):\n",
    "\n",
    "            temp_y = XB[:, j].reshape((-1, 1))\n",
    "            temp_y = temp_y + err.reshape((-1, 1))\n",
    "            temp_X = X[:, j].reshape((-1, 1))\n",
    "            type_name, term_instance = term_mapping[j]  \n",
    "\n",
    "            if type_name not in ['LinearTerm', 'ConstantTerm']:\n",
    "                gscr = lambda x: sm.OLS(y, np.hstack((term_instance.cal(x)))).fit().aic\n",
    "                sig = golden_section(term_instance.lower_bound, term_instance.upper_bound, 0.3879, gscr, 1e-2, 50, 50)[0]\n",
    "                sigs[j-1] = sig\n",
    "                sv = term_instance.cal(sig) # new smoothed values\n",
    "                X[:, j] = sv.flatten()\n",
    "                temp_X = sv.flatten().reshape((-1,1))\n",
    "\n",
    "            beta = _compute_betas_gwr(temp_y, temp_X, w.reshape((-1,1)))[0]\n",
    "            yhat = np.dot(temp_X, beta)\n",
    "            new_XB[:, j] = yhat.flatten()\n",
    "            err = (temp_y - yhat).reshape((-1, 1))\n",
    "            params[j, :] = beta[0][0]\n",
    "\n",
    "        num = np.sum((XB-new_XB)**2)\n",
    "        den = 1 + np.sum(np.sum(XB, axis=1)**2)\n",
    "        score = (num / den)\n",
    "        XB = new_XB\n",
    "\n",
    "        scores.append(deepcopy(score))\n",
    "        delta = score\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Current iteration:\", n_iter, \",SOC:\", np.round(score, 8))\n",
    "        if delta < tol:\n",
    "            break\n",
    "\n",
    "    return params, X, sigs\n",
    "\n",
    "def calibrate_Gaussian(y, X, term_mapping, verbose = False, max_iter = 50, crit_threshold = 1e-8):\n",
    "    \n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "\n",
    "    sigmas = [-1, -1]\n",
    "\n",
    "    s_0 = np.mean(y)\n",
    "    eta = s_0.reshape((-1, 1))\n",
    "    s_old = np.ones_like(X)\n",
    "    crit = 9999\n",
    "    n_iter = 0\n",
    "\n",
    "    while crit > crit_threshold and n_iter < max_iter:\n",
    "        w = np.ones(X.shape[0])\n",
    "        z = y.reshape((-1, 1))\n",
    "        betas, X, sigmas = classic_backfit(z, X, w, term_mapping = term_mapping, verbose = verbose, max_iter = max_iter, tol = crit_threshold) \n",
    "\n",
    "        s_new = np.multiply(betas.T, X)\n",
    "        inner = np.sum((s_old - s_new)**2, axis=1)\n",
    "        num = np.sum(w*inner)\n",
    "        den = np.sum(w*np.sum((1 + s_old)**2, axis=1).reshape((-1, 1)))\n",
    "        crit = num / den\n",
    "        eta = np.sum(s_new, axis=1).reshape((-1, 1))\n",
    "        s_old = s_new\n",
    "\n",
    "        n_iter += 1  # increment the iteration counter\n",
    "    return betas, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68360d89-5636-4647-a40f-7becff656c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_write_results_classic(sigma1, sigma2):\n",
    "\n",
    "    # Convert sigma1 and sigma2 to a string suitable for the filename\n",
    "    sigma1_str = format_sigma_for_filename(sigma1)\n",
    "    sigma2_str = format_sigma_for_filename(sigma2)\n",
    "    filename = f\"../results/0%Noise_classic_{sigma1_str}_{sigma2_str}.csv\"\n",
    "\n",
    "    with open(filename, \"a\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Check if file is empty and write headers\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writerow([\"beta_x1\", \"beta_s_x2\", \"beta_s_pois\", \"sigma_s_x2\", \"sigma_s_pois\"])\n",
    "\n",
    "        # 1. Implement 100 Simulations\n",
    "        n_iter = 0 # track iterations\n",
    "        for i in range(100): # i is also the seed \n",
    "            # Spatial Systems\n",
    "            np.random.seed(i)\n",
    "            square = Polygon([Point((0, 0)), Point((0, 2000)), Point((2000, 2000)), Point((2000, 0))])\n",
    "            squwin = as_window(square)\n",
    "\n",
    "            # Stations\n",
    "            np.random.seed(i)\n",
    "            squsamples = PoissonPointProcess(squwin, 150, 1, conditioning=False, asPP=False)\n",
    "            squpts_random = squsamples.realizations[0]\n",
    "\n",
    "            # DataFrame for Stations\n",
    "            random_df = pd.DataFrame(squpts_random, columns = ['Lon', 'Lat'])\n",
    "            random_df = random_df.assign(Name = np.arange(random_df.shape[0]))\n",
    "            digits = len(str(150))\n",
    "            random_df.Name = random_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('R', x))\n",
    "\n",
    "            # Add attributes, X1 and X2, for Stations\n",
    "            attr1 = np.random.uniform(2, 100, 150)\n",
    "            attr2 = np.random.uniform(100, 500, 150)\n",
    "\n",
    "            random_df = random_df.assign(X1 = attr1, X2 = attr2)\n",
    "\n",
    "            # POIs\n",
    "            np.random.seed(i * 2)\n",
    "            squsamples_pois = PoissonPointProcess(squwin, 900, 1, conditioning=False, asPP=False)\n",
    "            squpts_pois = squsamples_pois.realizations[0]\n",
    "\n",
    "            # DataFrame for POIs\n",
    "            pois_df = pd.DataFrame(squpts_pois, columns = ['Lon', 'Lat'])\n",
    "            pois_df = pois_df.assign(Name = np.arange(pois_df.shape[0]))\n",
    "            digits = len(str(900))\n",
    "            pois_df.Name = pois_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('I', x))\n",
    "\n",
    "            # Add attribute for POIs\n",
    "            attrI = np.ones(pois_df.shape[0])\n",
    "            pois_df = pois_df.assign(AttributeI = attrI)\n",
    "\n",
    "            # Necessary data for constructing `LinearTerm` of X1, and `DistanceWeighting` smoother of X2\n",
    "            dta_simul = random_df[['Name', 'X1', 'X2']]\n",
    "            dta_simul_gdf = random_df[['Name', 'Lon', 'Lat']]\n",
    "            dta_simul_gdf = gpd.GeoDataFrame(dta_simul_gdf.copy(), geometry=gpd.points_from_xy(dta_simul_gdf.Lon, dta_simul_gdf.Lat))\n",
    "\n",
    "            # Necessary data for constructing `DistanceWeighting` smoother of POIs\n",
    "            pois_simul_df = pois_df[['Name', 'AttributeI']]\n",
    "            pois_simul_gdf = pois_df[['Name', 'Lon', 'Lat']]\n",
    "            pois_simul_gdf = gpd.GeoDataFrame(pois_simul_gdf.copy(), geometry=gpd.points_from_xy(pois_simul_gdf.Lon, pois_simul_gdf.Lat))\n",
    "            map_simul_gdf = pd.concat([dta_simul_gdf, pois_simul_gdf]) # A map includes both the stations and POIs \n",
    "\n",
    "            # Construct spatial smoothers for X1, X2 and POIs\n",
    "            lin_simul = LinearTerm(dta_simul, 1, standard = True) # X1\n",
    "            sws_simul_X2 = SpatialWeightSmoother(dta_simul, dta_simul_gdf, [0,0,2], standard = True) # smoothing X2\n",
    "            dw_simul_pois = DistanceWeighting(dta_simul, map_simul_gdf, pois_simul_df, [0,0,0,1], standard = True)# smoothing POI\n",
    "\n",
    "            # Set the true values of distance decay parameters using the function arguments\n",
    "            s_X2_simul = sws_simul_X2.cal(sigma1) # Use sigma1 here\n",
    "            s_POIs_simul = dw_simul_pois.cal(sigma2) # Use sigma2 here\n",
    "\n",
    "            # Set the true values of coefficients for X1, s(X2), and s(POIs)\n",
    "            coefs_simul = [1,1,1] \n",
    "\n",
    "            # Generate y without noise\n",
    "            np.random.seed(i)\n",
    "            X_simul = np.hstack((lin_simul.X, s_X2_simul, s_POIs_simul)) \n",
    "            y_fitted = np.dot(X_simul, coefs_simul).reshape(-1,1)\n",
    "\n",
    "            # Fit calssic backfitting model\n",
    "            term_mapping = {}\n",
    "            term_mapping [0] = (type(lin_simul).__name__, lin_simul)  \n",
    "            term_mapping [1] = (type(sws_simul_X2).__name__, sws_simul_X2)   \n",
    "            term_mapping [2] = (type(dw_simul_pois).__name__, dw_simul_pois)  \n",
    "\n",
    "            initial_X_simul = np.hstack((lin_simul.X, sws_simul_X2.cal(-1), dw_simul_pois.cal(-1)))\n",
    "\n",
    "            coefs, sigs = calibrate_Gaussian(y_fitted, initial_X_simul, term_mapping)\n",
    "\n",
    "            # Store results\n",
    "            beta_x1 = pd.to_numeric(coefs[0].item())\n",
    "            beta_s_x2 = pd.to_numeric(coefs[1].item())\n",
    "            beta_s_pois = pd.to_numeric(coefs[2].item())\n",
    "            sigma_s_x2 = pd.to_numeric(sigs[0].item())\n",
    "            sigma_s_pois = pd.to_numeric(sigs[1].item())\n",
    "            #print(beta_x1, beta_s_x2, beta_s_pois, sigma_s_x2, sigma_s_pois)\n",
    " \n",
    "            writer.writerow([beta_x1, beta_s_x2, beta_s_pois, sigma_s_x2, sigma_s_pois])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331738cd-99c5-410e-84f2-99217e6c69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_write_results_modified(sigma1, sigma2):\n",
    "    # Convert sigma1 and sigma2 to a string suitable for the filename\n",
    "    sigma1_str = format_sigma_for_filename(sigma1)\n",
    "    sigma2_str = format_sigma_for_filename(sigma2)\n",
    "    filename = f\"../results/0%Noise_{sigma1_str}_{sigma2_str}.csv\"\n",
    "    \n",
    "    with open(filename, \"a\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Check if file is empty and write headers\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writerow([\"beta_x1\", \"beta_s_x2\", \"beta_s_pois\", \"sigma_s_x2\", \"sigma_s_pois\"])\n",
    "        \n",
    "        # 1. Implement 100 Simulations\n",
    "        n_iter = 0 # track iterations\n",
    "        for i in range(100): # i is also the seed \n",
    "            # Spatial Systems\n",
    "            np.random.seed(i)\n",
    "            square = Polygon([Point((0, 0)), Point((0, 2000)), Point((2000, 2000)), Point((2000, 0))])\n",
    "            squwin = as_window(square)\n",
    "\n",
    "            # Stations\n",
    "            np.random.seed(i)\n",
    "            squsamples = PoissonPointProcess(squwin, 150, 1, conditioning=False, asPP=False)\n",
    "            squpts_random = squsamples.realizations[0]\n",
    "\n",
    "            # DataFrame for Stations\n",
    "            random_df = pd.DataFrame(squpts_random, columns = ['Lon', 'Lat'])\n",
    "            random_df = random_df.assign(Name = np.arange(random_df.shape[0]))\n",
    "            digits = len(str(150))\n",
    "            random_df.Name = random_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('R', x))\n",
    "\n",
    "            # Add attributes, X1 and X2, for Stations\n",
    "            attr1 = np.random.uniform(2, 100, 150)\n",
    "            attr2 = np.random.uniform(100, 500, 150)\n",
    "\n",
    "            random_df = random_df.assign(X1 = attr1, X2 = attr2)\n",
    "\n",
    "            # POIs\n",
    "            np.random.seed(i * 2)\n",
    "            squsamples_pois = PoissonPointProcess(squwin, 900, 1, conditioning=False, asPP=False)\n",
    "            squpts_pois = squsamples_pois.realizations[0]\n",
    "\n",
    "            # DataFrame for POIs\n",
    "            pois_df = pd.DataFrame(squpts_pois, columns = ['Lon', 'Lat'])\n",
    "            pois_df = pois_df.assign(Name = np.arange(pois_df.shape[0]))\n",
    "            digits = len(str(900))\n",
    "            pois_df.Name = pois_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('I', x))\n",
    "\n",
    "            # Add attribute for POIs\n",
    "            attrI = np.ones(pois_df.shape[0])\n",
    "            pois_df = pois_df.assign(AttributeI = attrI)\n",
    "\n",
    "            # Necessary data for constructing `LinearTerm` of X1, and `DistanceWeighting` smoother of X2\n",
    "            dta_simul = random_df[['Name', 'X1', 'X2']]\n",
    "            dta_simul_gdf = random_df[['Name', 'Lon', 'Lat']]\n",
    "            dta_simul_gdf = gpd.GeoDataFrame(dta_simul_gdf.copy(), geometry=gpd.points_from_xy(dta_simul_gdf.Lon, dta_simul_gdf.Lat))\n",
    "\n",
    "            # Necessary data for constructing `DistanceWeighting` smoother of POIs\n",
    "            pois_simul_df = pois_df[['Name', 'AttributeI']]\n",
    "            pois_simul_gdf = pois_df[['Name', 'Lon', 'Lat']]\n",
    "            pois_simul_gdf = gpd.GeoDataFrame(pois_simul_gdf.copy(), geometry=gpd.points_from_xy(pois_simul_gdf.Lon, pois_simul_gdf.Lat))\n",
    "            map_simul_gdf = pd.concat([dta_simul_gdf, pois_simul_gdf]) # A map includes both the stations and POIs \n",
    "\n",
    "            # Construct spatial smoothers for X1, X2 and POIs\n",
    "            lin_simul = LinearTerm(dta_simul, 1, standard = True) # X1\n",
    "            sws_simul_X2 = SpatialWeightSmoother(dta_simul, dta_simul_gdf, [0,0,2], standard = True) # smoothing X2\n",
    "            dw_simul_pois = DistanceWeighting(dta_simul, map_simul_gdf, pois_simul_df, [0,0,0,1], standard = True)# smoothing POI\n",
    "\n",
    "            # Set the true values of distance decay parameters using the function arguments\n",
    "            s_X2_simul = sws_simul_X2.cal(sigma1) # Use sigma1 here\n",
    "            s_POIs_simul = dw_simul_pois.cal(sigma2) # Use sigma2 here\n",
    "\n",
    "            # Set the true values of coefficients for X1, s(X2), and s(POIs)\n",
    "            coefs_simul = [1,1,1] \n",
    "\n",
    "            # Generate y with adding 5% noise \n",
    "            np.random.seed(i)\n",
    "            X_simul = np.hstack((lin_simul.X, s_X2_simul, s_POIs_simul)) \n",
    "            y_fitted = np.dot(X_simul, coefs_simul).reshape(-1,1)\n",
    "            \n",
    "            # Fit GASS model\n",
    "            gass_simul = GASS(y_fitted, lin_simul, sws_simul_X2, dw_simul_pois, constant = False)\n",
    "            gass_simul.fit_Gaussian()\n",
    "\n",
    "            # Store results\n",
    "            beta_x1 = pd.to_numeric(gass_simul.coefficients[0].item())\n",
    "            beta_s_x2 = pd.to_numeric(gass_simul.coefficients[1].item())\n",
    "            beta_s_pois = pd.to_numeric(gass_simul.coefficients[2].item())\n",
    "            sigma_s_x2 = pd.to_numeric(gass_simul.sigmas[0].item())\n",
    "            sigma_s_pois = pd.to_numeric(gass_simul.sigmas[1].item())\n",
    "            \n",
    "            writer.writerow([beta_x1, beta_s_x2, beta_s_pois, sigma_s_x2, sigma_s_pois])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319a0331-878e-4bfe-ae8d-9b65a4a8419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the combination of sigma1 = -0.5 & sigma 2 = -1.5\n",
    "# Results are stored in 'results' folder, called \"0%Noise_classic_pt5_1.csv\" & \"0%Noise_pt5_1.csv\", respectively\n",
    "\n",
    "simulate_and_write_results_classic(-0.5, -1.5)\n",
    "simulate_and_write_results_modified(-0.5, -1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f577e37-4f15-411e-91e0-e36bce34c37c",
   "metadata": {},
   "source": [
    "# Repeated Simulations with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a279fa-952e-4806-bd16-18cc85d8aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the error term's standard deviation with p*100 % noise levels\n",
    "\n",
    "def error_term_sdd(y_fitted, p):\n",
    "    # Calculate variance of y_fitted\n",
    "    var_systematic = np.var(y_fitted)\n",
    "    \n",
    "    # Calculate variance of error term using the derived formula\n",
    "    var_error = p * var_systematic / (1-p)\n",
    "    \n",
    "    # Return standard deviation of the error term\n",
    "    return np.sqrt(var_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d4ea26-08f1-41d9-9afe-92f66f358058",
   "metadata": {},
   "source": [
    "## 5% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e14e428-ae0a-4b4c-a655-e15b824b21a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"../results/5%Noise.csv\", \"a\", newline='') as csvfile_5:\n",
    "    writer = csv.writer(csvfile_5)\n",
    "    \n",
    "    # Check if file is empty and write headers\n",
    "    if csvfile_5.tell() == 0:\n",
    "        writer.writerow([\"beta_x1\", \"beta_s_x2\", \"beta_s_pois\", \"sigma_s_x2\", \"sigma_s_pois\", \n",
    "                         \"lb_awci_sigma_s_x2\", \"ub_awci_sigma_s_x2\", \"lb_awci_sigma_s_pois\", \"ub_awci_sigma_s_pois\",\n",
    "                         \"lb_rbci_sigma_s_x2\", \"ub_rbci_sigma_s_x2\", \"lb_rbci_sigma_s_pois\", \"ub_rbci_sigma_s_pois\"])\n",
    "    \n",
    "    # 1. Implement 100 Simulations\n",
    "    n_iter = 0 # track iterations\n",
    "    for i in range(100): # i is also the seed \n",
    "\n",
    "        # Spatial Systems\n",
    "        np.random.seed(i)\n",
    "        square = Polygon([Point((0, 0)), Point((0, 2000)), Point((2000, 2000)), Point((2000, 0))])\n",
    "        squwin = as_window(square)\n",
    "\n",
    "        # Stations\n",
    "        np.random.seed(i)\n",
    "        squsamples = PoissonPointProcess(squwin, 150, 1, conditioning=False, asPP=False)\n",
    "        squpts_random = squsamples.realizations[0]\n",
    "\n",
    "        # DataFrame for Stations\n",
    "        random_df = pd.DataFrame(squpts_random, columns = ['Lon', 'Lat'])\n",
    "        random_df = random_df.assign(Name = np.arange(random_df.shape[0]))\n",
    "        digits = len(str(150))\n",
    "        random_df.Name = random_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('R', x))\n",
    "\n",
    "        # Add attributes, X1 and X2, for Stations\n",
    "        attr1 = np.random.uniform(2, 100, 150)\n",
    "        attr2 = np.random.uniform(100, 500, 150)\n",
    "\n",
    "        random_df = random_df.assign(X1 = attr1, X2 = attr2)\n",
    "\n",
    "        # POIs\n",
    "        np.random.seed(i * 2)\n",
    "        squsamples_pois = PoissonPointProcess(squwin, 900, 1, conditioning=False, asPP=False)\n",
    "        squpts_pois = squsamples_pois.realizations[0]\n",
    "\n",
    "        # DataFrame for POIs\n",
    "        pois_df = pd.DataFrame(squpts_pois, columns = ['Lon', 'Lat'])\n",
    "        pois_df = pois_df.assign(Name = np.arange(pois_df.shape[0]))\n",
    "        digits = len(str(900))\n",
    "        pois_df.Name = pois_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('I', x))\n",
    "\n",
    "        # Add attribute for POIs\n",
    "        attrI = np.ones(pois_df.shape[0])\n",
    "        pois_df = pois_df.assign(AttributeI = attrI)\n",
    "\n",
    "        # Necessary data for constructing `LinearTerm` of X1, and `DistanceWeighting` smoother of X2\n",
    "        dta_simul = random_df[['Name', 'X1', 'X2']]\n",
    "        dta_simul_gdf = random_df[['Name', 'Lon', 'Lat']]\n",
    "        dta_simul_gdf = gpd.GeoDataFrame(dta_simul_gdf.copy(), geometry=gpd.points_from_xy(dta_simul_gdf.Lon, dta_simul_gdf.Lat))\n",
    "\n",
    "        # Necessary data for constructing `DistanceWeighting` smoother of POIs\n",
    "        pois_simul_df = pois_df[['Name', 'AttributeI']]\n",
    "        pois_simul_gdf = pois_df[['Name', 'Lon', 'Lat']]\n",
    "        pois_simul_gdf = gpd.GeoDataFrame(pois_simul_gdf.copy(), geometry=gpd.points_from_xy(pois_simul_gdf.Lon, pois_simul_gdf.Lat))\n",
    "        map_simul_gdf = pd.concat([dta_simul_gdf, pois_simul_gdf]) # A map includes both the stations and POIs \n",
    "\n",
    "        # Construct spatial smoothers for X1, X2 and POIs\n",
    "        lin_simul = LinearTerm(dta_simul, 1, standard = True) # X1\n",
    "        sws_simul_X2 = SpatialWeightSmoother(dta_simul, dta_simul_gdf, [0,0,2], standard = True) # smoothing X2\n",
    "        dw_simul_pois = DistanceWeighting(dta_simul, map_simul_gdf, pois_simul_df, [0,0,0,1], standard = True)# smoothing POI\n",
    "\n",
    "        # Set the true values of distance decay parameters for s(X2) and s(POIs)\n",
    "        s_X2_simul = sws_simul_X2.cal(-0.5) #s(X2)\n",
    "        s_POIs_simul = dw_simul_pois.cal(-1.5) #s(POIs)\n",
    "\n",
    "        # Set the true values of coefficients for X1, s(X2), and s(POIs)\n",
    "        coefs_simul = [1,1,1] \n",
    "\n",
    "        # Generate y with adding 5% noise \n",
    "        np.random.seed(i)\n",
    "        X_simul = np.hstack((lin_simul.X, s_X2_simul, s_POIs_simul)) \n",
    "        y_fitted = np.dot(X_simul, coefs_simul).reshape(-1,1)\n",
    "        y_simul = y_fitted + np.random.normal(0, error_term_sdd(y_fitted, 0.05), (dta_simul.shape[0],1)).reshape(-1,1) # 0.05: 5%\n",
    "\n",
    "        # Fit GASS model\n",
    "        gass_simul = GASS(y_simul, lin_simul, sws_simul_X2, dw_simul_pois, constant = False)\n",
    "        gass_simul.fit_Gaussian()\n",
    "        gass_simul.inference_Gaussian()\n",
    "        gass_simul.calculate_AWCI_sigmas()\n",
    "        gass_simul.calculate_RBCI_sigmas(max_iter = 100)\n",
    "        \n",
    "        # Store results\n",
    "        beta_x1 = pd.to_numeric(gass_simul.coefficients[0][0])\n",
    "        beta_s_x2 = pd.to_numeric(gass_simul.coefficients[1][0])\n",
    "        beta_s_pois = pd.to_numeric(gass_simul.coefficients[2][0])\n",
    "        sigma_s_x2 = pd.to_numeric(gass_simul.sigmas[0])\n",
    "        sigma_s_pois = pd.to_numeric(gass_simul.sigmas[1])\n",
    "        \n",
    "        lb_awci_sigma_s_x2 = pd.to_numeric(gass_simul.AWCI_sigmas[0][0])\n",
    "        ub_awci_sigma_s_x2 = pd.to_numeric(gass_simul.AWCI_sigmas[0][1])       \n",
    "        lb_awci_sigma_s_pois = pd.to_numeric(gass_simul.AWCI_sigmas[1][0])\n",
    "        ub_awci_sigma_s_pois = pd.to_numeric(gass_simul.AWCI_sigmas[1][1])\n",
    "        \n",
    "        lb_rbci_sigma_s_x2 = pd.to_numeric(gass_simul.RBCI_sigmas[0][0])\n",
    "        ub_rbci_sigma_s_x2 = pd.to_numeric(gass_simul.RBCI_sigmas[0][1])\n",
    "        lb_rbci_sigma_s_pois = pd.to_numeric(gass_simul.RBCI_sigmas[1][0])\n",
    "        ub_rbci_sigma_s_pois = pd.to_numeric(gass_simul.RBCI_sigmas[1][1]) \n",
    "\n",
    "        # Write results to the CSV file\n",
    "        writer.writerow([beta_x1, beta_s_x2, beta_s_pois, sigma_s_x2, sigma_s_pois, \n",
    "                         lb_awci_sigma_s_x2, ub_awci_sigma_s_x2, lb_awci_sigma_s_pois, ub_awci_sigma_s_pois,\n",
    "                         lb_rbci_sigma_s_x2, ub_rbci_sigma_s_x2, lb_rbci_sigma_s_pois, ub_rbci_sigma_s_pois])\n",
    "\n",
    "        # Track iteration progress\n",
    "        print(n_iter)\n",
    "        n_iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce62a2d1-eae6-4c4c-9652-85bf3f7a058e",
   "metadata": {},
   "source": [
    "## 10% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0299a11d-fff7-4129-a2ae-baae72f9c551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "with open(\"../results/10%Noise.csv\", \"a\", newline='') as csvfile_10:\n",
    "    writer = csv.writer(csvfile_10)\n",
    "    \n",
    "    # Check if file is empty and write headers\n",
    "    if csvfile_10.tell() == 0:\n",
    "        writer.writerow([\"beta_x1\", \"beta_s_x2\", \"beta_s_pois\", \"sigma_s_x2\", \"sigma_s_pois\", \n",
    "                         \"lb_awci_sigma_s_x2\", \"ub_awci_sigma_s_x2\", \"lb_awci_sigma_s_pois\", \"ub_awci_sigma_s_pois\",\n",
    "                         \"lb_rbci_sigma_s_x2\", \"ub_rbci_sigma_s_x2\", \"lb_rbci_sigma_s_pois\", \"ub_rbci_sigma_s_pois\"])\n",
    "        \n",
    "    # 1. Implement 100 Simulations\n",
    "    n_iter = 0 # track iterations\n",
    "    for i in range(100): # i is also the seed \n",
    "\n",
    "        # Spatial Systems\n",
    "        np.random.seed(i)\n",
    "        square = Polygon([Point((0, 0)), Point((0, 2000)), Point((2000, 2000)), Point((2000, 0))])\n",
    "        squwin = as_window(square)\n",
    "\n",
    "        # Stations\n",
    "        np.random.seed(i)\n",
    "        squsamples = PoissonPointProcess(squwin, 150, 1, conditioning=False, asPP=False)\n",
    "        squpts_random = squsamples.realizations[0]\n",
    "\n",
    "        # DataFrame for Stations\n",
    "        random_df = pd.DataFrame(squpts_random, columns = ['Lon', 'Lat'])\n",
    "        random_df = random_df.assign(Name = np.arange(random_df.shape[0]))\n",
    "        digits = len(str(150))\n",
    "        random_df.Name = random_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('R', x))\n",
    "\n",
    "        # Add attributes, X1 and X2, for Stations\n",
    "        attr1 = np.random.uniform(2, 100, 150)\n",
    "        attr2 = np.random.uniform(100, 500, 150)\n",
    "\n",
    "        random_df = random_df.assign(X1 = attr1, X2 = attr2)\n",
    "\n",
    "        # POIs\n",
    "        np.random.seed(i * 2)\n",
    "        squsamples_pois = PoissonPointProcess(squwin, 900, 1, conditioning=False, asPP=False)\n",
    "        squpts_pois = squsamples_pois.realizations[0]\n",
    "\n",
    "        # DataFrame for POIs\n",
    "        pois_df = pd.DataFrame(squpts_pois, columns = ['Lon', 'Lat'])\n",
    "        pois_df = pois_df.assign(Name = np.arange(pois_df.shape[0]))\n",
    "        digits = len(str(900))\n",
    "        pois_df.Name = pois_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('I', x))\n",
    "\n",
    "        # Add attribute for POIs\n",
    "        attrI = np.ones(pois_df.shape[0])\n",
    "        pois_df = pois_df.assign(AttributeI = attrI)\n",
    "\n",
    "        # Necessary data for constructing `LinearTerm` of X1, and `DistanceWeighting` smoother of X2\n",
    "        dta_simul = random_df[['Name', 'X1', 'X2']]\n",
    "        dta_simul_gdf = random_df[['Name', 'Lon', 'Lat']]\n",
    "        dta_simul_gdf = gpd.GeoDataFrame(dta_simul_gdf.copy(), geometry=gpd.points_from_xy(dta_simul_gdf.Lon, dta_simul_gdf.Lat))\n",
    "\n",
    "        # Necessary data for constructing `DistanceWeighting` smoother of POIs\n",
    "        pois_simul_df = pois_df[['Name', 'AttributeI']]\n",
    "        pois_simul_gdf = pois_df[['Name', 'Lon', 'Lat']]\n",
    "        pois_simul_gdf = gpd.GeoDataFrame(pois_simul_gdf.copy(), geometry=gpd.points_from_xy(pois_simul_gdf.Lon, pois_simul_gdf.Lat))\n",
    "        map_simul_gdf = pd.concat([dta_simul_gdf, pois_simul_gdf]) # A map includes both the stations and POIs \n",
    "\n",
    "        # Construct spatial smoothers for X1, X2 and POIs\n",
    "        lin_simul = LinearTerm(dta_simul, 1, standard = True) # X1\n",
    "        sws_simul_X2 = SpatialWeightSmoother(dta_simul, dta_simul_gdf, [0,0,2], standard = True) # smoothing X2\n",
    "        dw_simul_pois = DistanceWeighting(dta_simul, map_simul_gdf, pois_simul_df, [0,0,0,1], standard = True)# smoothing POI\n",
    "\n",
    "        # Set the true values of distance decay parameters for s(X2) and s(POIs)\n",
    "        s_X2_simul = sws_simul_X2.cal(-0.5) #s(X2)\n",
    "        s_POIs_simul = dw_simul_pois.cal(-1.5) #s(POIs)\n",
    "\n",
    "        # Set the true values of coefficients for X1, s(X2), and s(POIs)\n",
    "        coefs_simul = [1,1,1] \n",
    "\n",
    "        # Generate y with adding 10% noise \n",
    "        np.random.seed(i)\n",
    "        X_simul = np.hstack((lin_simul.X, s_X2_simul, s_POIs_simul)) \n",
    "        y_fitted = np.dot(X_simul, coefs_simul).reshape(-1,1)\n",
    "        y_simul = y_fitted + np.random.normal(0, error_term_sdd(y_fitted, 0.10), (dta_simul.shape[0],1)).reshape(-1,1) # 0.10: 10%\n",
    "\n",
    "        # Fit GASS model\n",
    "        gass_simul = GASS(y_simul, lin_simul, sws_simul_X2, dw_simul_pois, constant = False)\n",
    "        gass_simul.fit_Gaussian()\n",
    "        gass_simul.inference_Gaussian()\n",
    "        gass_simul.calculate_AWCI_sigmas()\n",
    "        gass_simul.calculate_RBCI_sigmas(max_iter = 100)\n",
    "\n",
    "        # Store results\n",
    "        beta_x1 = pd.to_numeric(gass_simul.coefficients[0][0])\n",
    "        beta_s_x2 = pd.to_numeric(gass_simul.coefficients[1][0])\n",
    "        beta_s_pois = pd.to_numeric(gass_simul.coefficients[2][0])\n",
    "        sigma_s_x2 = pd.to_numeric(gass_simul.sigmas[0])\n",
    "        sigma_s_pois = pd.to_numeric(gass_simul.sigmas[1])\n",
    "        \n",
    "        lb_awci_sigma_s_x2 = pd.to_numeric(gass_simul.AWCI_sigmas[0][0])\n",
    "        ub_awci_sigma_s_x2 = pd.to_numeric(gass_simul.AWCI_sigmas[0][1])     \n",
    "        lb_awci_sigma_s_pois = pd.to_numeric(gass_simul.AWCI_sigmas[1][0])\n",
    "        ub_awci_sigma_s_pois = pd.to_numeric(gass_simul.AWCI_sigmas[1][1])\n",
    "        \n",
    "        lb_rbci_sigma_s_x2 = pd.to_numeric(gass_simul.RBCI_sigmas[0][0])\n",
    "        ub_rbci_sigma_s_x2 = pd.to_numeric(gass_simul.RBCI_sigmas[0][1])\n",
    "        lb_rbci_sigma_s_pois = pd.to_numeric(gass_simul.RBCI_sigmas[1][0])\n",
    "        ub_rbci_sigma_s_pois = pd.to_numeric(gass_simul.RBCI_sigmas[1][1]) \n",
    "\n",
    "        # Write results to the CSV file\n",
    "        writer.writerow([beta_x1, beta_s_x2, beta_s_pois, sigma_s_x2, sigma_s_pois, \n",
    "                         lb_awci_sigma_s_x2, ub_awci_sigma_s_x2, lb_awci_sigma_s_pois, ub_awci_sigma_s_pois,\n",
    "                         lb_rbci_sigma_s_x2, ub_rbci_sigma_s_x2, lb_rbci_sigma_s_pois, ub_rbci_sigma_s_pois])\n",
    "\n",
    "        # Track iteration progress\n",
    "        print(n_iter)\n",
    "        n_iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4fbbf-5d4e-4a78-8c5f-db54f0249b8c",
   "metadata": {},
   "source": [
    "## 25% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7d402fe-b035-4081-8034-9cc7c1088dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "with open(\"../results/25%Noise.csv\", \"a\", newline='') as csvfile_25:\n",
    "    writer = csv.writer(csvfile_25)\n",
    "    \n",
    "    # Check if file is empty and write headers\n",
    "    if csvfile_25.tell() == 0:\n",
    "        writer.writerow([\"beta_x1\", \"beta_s_x2\", \"beta_s_pois\", \"sigma_s_x2\", \"sigma_s_pois\", \n",
    "                         \"lb_awci_sigma_s_x2\", \"ub_awci_sigma_s_x2\", \"lb_awci_sigma_s_pois\", \"ub_awci_sigma_s_pois\",\n",
    "                         \"lb_rbci_sigma_s_x2\", \"ub_rbci_sigma_s_x2\", \"lb_rbci_sigma_s_pois\", \"ub_rbci_sigma_s_pois\"])\n",
    "        \n",
    "    # 1. Implement 100 Simulations\n",
    "    n_iter = 0 # track iterations\n",
    "    for i in range(2): # i is also the seed \n",
    "\n",
    "        # Spatial Systems\n",
    "        np.random.seed(i)\n",
    "        square = Polygon([Point((0, 0)), Point((0, 2000)), Point((2000, 2000)), Point((2000, 0))])\n",
    "        squwin = as_window(square)\n",
    "\n",
    "        # Stations\n",
    "        np.random.seed(i)\n",
    "        squsamples = PoissonPointProcess(squwin, 150, 1, conditioning=False, asPP=False)\n",
    "        squpts_random = squsamples.realizations[0]\n",
    "\n",
    "        # DataFrame for Stations\n",
    "        random_df = pd.DataFrame(squpts_random, columns = ['Lon', 'Lat'])\n",
    "        random_df = random_df.assign(Name = np.arange(random_df.shape[0]))\n",
    "        digits = len(str(150))\n",
    "        random_df.Name = random_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('R', x))\n",
    "\n",
    "        # Add attributes, X1 and X2, for Stations\n",
    "        attr1 = np.random.uniform(2, 100, 150)\n",
    "        attr2 = np.random.uniform(100, 500, 150)\n",
    "\n",
    "        random_df = random_df.assign(X1 = attr1, X2 = attr2)\n",
    "\n",
    "        # POIs\n",
    "        np.random.seed(i * 2)\n",
    "        squsamples_pois = PoissonPointProcess(squwin, 900, 1, conditioning=False, asPP=False)\n",
    "        squpts_pois = squsamples_pois.realizations[0]\n",
    "\n",
    "        # DataFrame for POIs\n",
    "        pois_df = pd.DataFrame(squpts_pois, columns = ['Lon', 'Lat'])\n",
    "        pois_df = pois_df.assign(Name = np.arange(pois_df.shape[0]))\n",
    "        digits = len(str(900))\n",
    "        pois_df.Name = pois_df.Name.astype(str).str.zfill(digits).apply(lambda x: \"{}{}\".format('I', x))\n",
    "\n",
    "        # Add attribute for POIs\n",
    "        attrI = np.ones(pois_df.shape[0])\n",
    "        pois_df = pois_df.assign(AttributeI = attrI)\n",
    "\n",
    "        # Necessary data for constructing `LinearTerm` of X1, and `DistanceWeighting` smoother of X2\n",
    "        dta_simul = random_df[['Name', 'X1', 'X2']]\n",
    "        dta_simul_gdf = random_df[['Name', 'Lon', 'Lat']]\n",
    "        dta_simul_gdf = gpd.GeoDataFrame(dta_simul_gdf.copy(), geometry=gpd.points_from_xy(dta_simul_gdf.Lon, dta_simul_gdf.Lat))\n",
    "\n",
    "        # Necessary data for constructing `DistanceWeighting` smoother of POIs\n",
    "        pois_simul_df = pois_df[['Name', 'AttributeI']]\n",
    "        pois_simul_gdf = pois_df[['Name', 'Lon', 'Lat']]\n",
    "        pois_simul_gdf = gpd.GeoDataFrame(pois_simul_gdf.copy(), geometry=gpd.points_from_xy(pois_simul_gdf.Lon, pois_simul_gdf.Lat))\n",
    "        map_simul_gdf = pd.concat([dta_simul_gdf, pois_simul_gdf]) # A map includes both the stations and POIs \n",
    "\n",
    "        # Construct spatial smoothers for X1, X2 and POIs\n",
    "        lin_simul = LinearTerm(dta_simul, 1, standard = True) #X1\n",
    "        sws_simul_X2 = SpatialWeightSmoother(dta_simul, dta_simul_gdf, [0,0,2], standard = True) # smoothing X2\n",
    "        dw_simul_pois = DistanceWeighting(dta_simul, map_simul_gdf, pois_simul_df, [0,0,0,1], standard = True)# smoothing POI\n",
    "\n",
    "        # Set the true values of distance decay parameters for s(X2) and s(POIs)\n",
    "        s_X2_simul = sws_simul_X2.cal(-0.5) # s(X2)\n",
    "        s_POIs_simul = dw_simul_pois.cal(-1.5) # s(POIs)\n",
    "\n",
    "        # Set the true values of coefficients for X1, s(X2), and s(POIs)\n",
    "        coefs_simul = [1,1,1] \n",
    "\n",
    "        # Generate y with adding 25% noise \n",
    "        np.random.seed(i)\n",
    "        X_simul = np.hstack((lin_simul.X, s_X2_simul, s_POIs_simul)) \n",
    "        y_fitted = np.dot(X_simul, coefs_simul).reshape(-1,1)\n",
    "        y_simul = y_fitted + np.random.normal(0, error_term_sdd(y_fitted, 0.25), (dta_simul.shape[0],1)).reshape(-1,1) # 0.25: 25%\n",
    "\n",
    "        # Fit GASS model\n",
    "        gass_simul = GASS(y_simul, lin_simul, sws_simul_X2, dw_simul_pois, constant = False)\n",
    "        gass_simul.fit_Gaussian()\n",
    "        gass_simul.inference_Gaussian()\n",
    "        gass_simul.calculate_AWCI_sigmas()\n",
    "        gass_simul.calculate_RBCI_sigmas(max_iter = 100)\n",
    "        \n",
    "        # Store results\n",
    "        beta_x1 = pd.to_numeric(gass_simul.coefficients[0][0])\n",
    "        beta_s_x2 = pd.to_numeric(gass_simul.coefficients[1][0])\n",
    "        beta_s_pois = pd.to_numeric(gass_simul.coefficients[2][0])\n",
    "        sigma_s_x2 = pd.to_numeric(gass_simul.sigmas[0])\n",
    "        sigma_s_pois = pd.to_numeric(gass_simul.sigmas[1])\n",
    "        \n",
    "        lb_awci_sigma_s_x2 = pd.to_numeric(gass_simul.AWCI_sigmas[0][0])\n",
    "        ub_awci_sigma_s_x2 = pd.to_numeric(gass_simul.AWCI_sigmas[0][1])       \n",
    "        lb_awci_sigma_s_pois = pd.to_numeric(gass_simul.AWCI_sigmas[1][0])\n",
    "        ub_awci_sigma_s_pois = pd.to_numeric(gass_simul.AWCI_sigmas[1][1])\n",
    "        \n",
    "        lb_rbci_sigma_s_x2 = pd.to_numeric(gass_simul.RBCI_sigmas[0][0])\n",
    "        ub_rbci_sigma_s_x2 = pd.to_numeric(gass_simul.RBCI_sigmas[0][1])\n",
    "        lb_rbci_sigma_s_pois = pd.to_numeric(gass_simul.RBCI_sigmas[1][0])\n",
    "        ub_rbci_sigma_s_pois = pd.to_numeric(gass_simul.RBCI_sigmas[1][1]) \n",
    "\n",
    "        # Write results to the CSV file\n",
    "        writer.writerow([beta_x1, beta_s_x2, beta_s_pois, sigma_s_x2, sigma_s_pois, \n",
    "                         lb_awci_sigma_s_x2, ub_awci_sigma_s_x2, lb_awci_sigma_s_pois, ub_awci_sigma_s_pois,\n",
    "                         lb_rbci_sigma_s_x2, ub_rbci_sigma_s_x2, lb_rbci_sigma_s_pois, ub_rbci_sigma_s_pois])\n",
    "\n",
    "        # Track iteration progress\n",
    "        print(n_iter)\n",
    "        n_iter+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
